<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Azure OpenAI Realtime Transcription Session</title>
</head>
<body>
    <h1>Azure OpenAI Realtime Transcription Session</h1>
    <p>WARNING: Don't use this code sample in production with the API key hardcoded. Use a protected backend service to call the sessions API and generate the ephemeral key. Then return the ephemeral key to the client.</p>
    <button onclick="StartSession()">Start Session</button>

    <!-- Log container for API messages -->
    <div id="logContainer"></div>

    <script>
        // Make sure the WebRTC URL region matches the region of your Azure OpenAI resource.
        // For example, if your Azure OpenAI resource is in the swedencentral region,
        // the WebRTC URL should be https://swedencentral.realtimeapi-preview.ai.azure.com/v1/realtimertc.
        // If your Azure OpenAI resource is in the eastus2 region, the WebRTC URL should be https://eastus2.realtimeapi-preview.ai.azure.com/v1/realtimertc.
        // IMPORTANT: Your resource URL shows 'eus2' which suggests eastus2 region - make sure this matches!
        const WEBRTC_URL = "https://eastus2.realtimeapi-preview.ai.azure.com/v1/realtimertc";

        // The SESSIONS_URL includes the Azure OpenAI resource URL,
        // deployment name, the /realtimeapi/transcription_sessions path, and the API version.
        // The Azure OpenAI resource region isn't part of the SESSIONS_URL.
        const SESSIONS_URL = "https://<>.openai.azure.com/openai/realtimeapi/transcription_sessions?api-version=2025-04-01-preview";

        // The API key of the Azure OpenAI resource.

        // The deployment name might not be the same as the model name.
        const DEPLOYMENT = "gpt-4o-transcribe";

        async function StartSession() {
            try {
                // WARNING: Don't use this code sample in production
                // with the API key hardcoded. 
                // Use a protected backend service to call the 
                // sessions API and generate the ephemeral key.
                // Then return the ephemeral key to the client.

                const response = await fetch(SESSIONS_URL, {
                    method: "POST",
                    headers: {
                        // The Authorization header is commented out because
                        // currently it isn't supported with the sessions API. 
                        //"Authorization": `Bearer ${ACCESS_TOKEN}`,
                        "api-key": API_KEY,
                        "Content-Type": "application/json"
                    },
                    body: JSON.stringify({
                        "input_audio_transcription": {
                            "model": "gpt-4o-transcribe",
                            "prompt": "You are a helpful assistant that transcribes meetings. Please only transcribe using this language code: en. Do not attempt to translate the text. Do not detect or switch to other languages."
                        }
                    })
                });

                if (!response.ok) {
                    const errorText = await response.text();
                    logMessage(`Sessions API Error: ${response.status} ${response.statusText}`);
                    logMessage(`Sessions API Error Body: ${errorText}`);
                    throw new Error(`Sessions API request failed: ${response.status} - ${errorText}`);
                }

                const data = await response.json();

                const sessionId = data.id;
                const ephemeralKey = data.client_secret?.value;
                console.error("Ephemeral key:", ephemeralKey);

                // Mask the ephemeral key in the log message.
                logMessage("Ephemeral Key Received: " + "***");
                logMessage("WebRTC Session Id = " + sessionId);

                // Validate the response data
                if (!sessionId) {
                    throw new Error("No session ID received from sessions API");
                }
                if (!ephemeralKey) {
                    throw new Error("No ephemeral key received from sessions API");
                }
                
                logMessage(`Session data validation passed`);
                logMessage(`Session ID length: ${sessionId.length}`);
                logMessage(`Ephemeral key length: ${ephemeralKey.length}`);

                // Set up the WebRTC connection using the ephemeral key.
                init(ephemeralKey);

            } catch (error) {
                console.error("Error fetching ephemeral key:", error);
                logMessage("Error fetching ephemeral key: " + error.message);
            }
        }

        async function init(ephemeralKey) {
            let peerConnection = new RTCPeerConnection();

            // Set up to play remote audio from the model.
            const audioElement = document.createElement('audio');
            audioElement.autoplay = true;
            document.body.appendChild(audioElement);

            peerConnection.ontrack = (event) => {
                audioElement.srcObject = event.streams[0];
            };

            // Set up data channel for sending and receiving events
            const clientMedia = await navigator.mediaDevices.getUserMedia({ audio: true });
            const audioTrack = clientMedia.getAudioTracks()[0];
            peerConnection.addTrack(audioTrack);

            const dataChannel = peerConnection.createDataChannel('realtime-channel');

            dataChannel.addEventListener('open', () => {
                logMessage('Data channel is open');
                updateSession(dataChannel);
            });

            dataChannel.addEventListener('message', (event) => {
                const realtimeEvent = JSON.parse(event.data);
                console.log(realtimeEvent);
                logMessage("Received server event: " + JSON.stringify(realtimeEvent, null, 2));
                
                if (realtimeEvent.type === "transcription_session.update") {
                    logMessage("Transcription session updated successfully");
                } else if (realtimeEvent.type === "transcription_session.error") {
                    logMessage("Error: " + realtimeEvent.error.message);
                } else if (realtimeEvent.type === "transcription_session.end") {
                    logMessage("Transcription session ended.");
                } else if (realtimeEvent.type === "conversation.item.input_audio_transcription.completed") {
                    logMessage("Transcription completed: " + realtimeEvent.transcript);
                } else if (realtimeEvent.type === "conversation.item.input_audio_transcription.failed") {
                    logMessage("Transcription failed: " + realtimeEvent.error?.message);
                }
            });

            dataChannel.addEventListener('close', () => {
                logMessage('Data channel is closed');
            });

            try {
                // Start the session using the Session Description Protocol (SDP)
                logMessage("Creating WebRTC offer...");
                const offer = await peerConnection.createOffer();
                await peerConnection.setLocalDescription(offer);

                // Debug the SDP offer
                logMessage(`SDP Offer created successfully`);
                logMessage(`SDP Offer type: ${offer.type}`);
                logMessage(`SDP Offer length: ${offer.sdp.length} characters`);
                logMessage(`SDP Offer first line: ${offer.sdp.split('\n')[0]}`);

                logMessage("Sending SDP offer to Azure...");
                logMessage("WebRTC URL: " + `${WEBRTC_URL}?api-version=2025-04-01-preview&intent=transcription&deployment=${DEPLOYMENT}`);
                logMessage("Ephemeral Key (masked): " + ephemeralKey.substring(0, 10) + "***");

                const sdpResponse = await fetch(`${WEBRTC_URL}?api-version=2025-04-01-preview&intent=transcription&deployment=${DEPLOYMENT}`, {
                    method: "POST",
                    body: offer.sdp,
                    headers: {
                        Authorization: `Bearer ${ephemeralKey}`,
                        "Content-Type": "application/sdp",
                    },
                });

                logMessage(`SDP Response Status: ${sdpResponse.status} ${sdpResponse.statusText}`);
                logMessage(`SDP Response Headers: ${JSON.stringify(Object.fromEntries(sdpResponse.headers))}`);

                const sdpText = await sdpResponse.text();
                logMessage(`Full SDP Response: ${sdpText}`);

                if (!sdpResponse.ok) {
                    logMessage(`WebRTC SDP Error Details: Status ${sdpResponse.status}`);
                    logMessage(`WebRTC SDP Error Body: ${sdpText}`);
                    logMessage(`Request URL: ${WEBRTC_URL}?model=${DEPLOYMENT}&intent=transcription`);
                    logMessage(`Request Headers: Authorization: Bearer ${ephemeralKey.substring(0, 10)}***, Content-Type: application/sdp`);
                    throw new Error(`SDP request failed with status ${sdpResponse.status}: ${sdpText}`);
                }

                if (!sdpText.startsWith('v=')) {
                    throw new Error(`Invalid SDP response. Expected SDP format but got: ${sdpText}`);
                }

                const answer = { type: "answer", sdp: sdpText };
                await peerConnection.setRemoteDescription(answer);

                logMessage("WebRTC connection established successfully!");

                const button = document.createElement('button');
                button.innerText = 'Close Session';
                button.onclick = stopSession;
                document.body.appendChild(button);

            } catch (error) {
                logMessage("Error setting up WebRTC connection: " + error.message);
                console.error("WebRTC setup error:", error);
                return;
            }

            // Send a client event to update the session
            function updateSession(dataChannel) {
                const event = {
                    type: "transcription_session.update",
                    session: {
                        "input_audio_format": "pcm16",
                        "input_audio_transcription": {
                            "model": "gpt-4o-transcribe",
                            "prompt": "Respond in English."
                        },
                        "turn_detection": {"type": "server_vad", "threshold": 0.5, "prefix_padding_ms": 300, "silence_duration_ms": 200}
                    }
                };
                dataChannel.send(JSON.stringify(event));
                logMessage("Sent client event: " + JSON.stringify(event, null, 2));
            }

            function stopSession() {
                if (dataChannel) dataChannel.close();
                if (peerConnection) peerConnection.close();
                peerConnection = null;
                logMessage("Session closed.");
            }
        }

        function logMessage(message) {
            const logContainer = document.getElementById("logContainer");
            const p = document.createElement("p");
            p.textContent = message;
            logContainer.appendChild(p);
        }
    </script>
</body>
</html>
